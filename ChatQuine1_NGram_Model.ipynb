{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1vagMenSzQYtSA5Jx39l9ENJpuRU6khQM",
      "authorship_tag": "ABX9TyOTpNXDr8qyz7hG4ml43RSk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mandi-Li/ChatQuine-TriGram-Model/blob/main/ChatQuine1_NGram_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ChatQuine: A Tri-Gram Language Model Simulating Philosopher Willard Van Orman Quine**"
      ],
      "metadata": {
        "id": "oluRFGff0273"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Programmer and Project Creator: **Mandi Li**\n",
        "\n",
        "\n",
        "University of Amsterdam\n",
        "\n",
        "\n",
        "Note: while this is ChatQuine1.0 trained on a tri-gram model, I also led by team to create **ChatQuine2.0 trained on the GPT3-turbo model**： https://github.com/Cameron-Meinsma/ChatQuine\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Djlzq5_4-Nd0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*Simulating the brain of philosopher Willard Van Orman Quine: What would Quine's perspective be on the contemporary philosophical challenges if he were alive today?\n",
        "\n",
        "By emulating Quine's linguistic and thinking patterns in an AI language model, our research represents an initial stride towards 'mind uploading,' a transhumanist proposition aimed at overcoming humanity's inherent flaw of mortality.*"
      ],
      "metadata": {
        "id": "QdzNpp8x1QYV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction**\n",
        "\n",
        "Created by Mandi Li, ChatQuine is a vertical philosophy chatbot that is capable of engaging in extensive philosophical discussions, explaining complicated philosophical concepts, and completing philosophical texts from the perspective of philosopher Quine. This is ChatQuine1.0 trained on a tri-gram language model.\n",
        "\n",
        "In many sci-fi movies, posthumans upload their consciousness into computers to achieve immortality. While today’s Artificial Intelligence (AI) cannot simulate human consciousness, AI language models are already capable of replicating human language patterns. As historian Yuval Noah Harari suggests, language is the foundation of human civilisation (2023).  Thus, AI’s mastery of language can provide us with a simulated copy of human culture.\n",
        "\n",
        "This research aims to delve into the mind of the philosopher Willard Van Orman Quine and explore how he would approach contemporary philosophical questions if he were alive today. Quine’s scientific approach to logic is still relevant in contemporary philosophical discourse. By emulating Quine's thinking patterns in a generative language model, I seek to simulate his cognitive processes and gain unique insights into his philosophical logic.\n",
        "Additionally, this research goes beyond philosophical exploration. It represents an initial stride towards 'mind uploading,' a transhumanist proposition aimed at overcoming humanity's inherent flaw of mortality. By emulating Quine's linguistic patterns in an AI language model, I aim to bridge the gap between human consciousness and machine intelligence, paving the way for preserving and continuing the intellectual legacy of great thinkers like Quine.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_KtwfDNm2e5i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset**\n",
        "\n",
        "Based on the fact that I want to train a generative language model in such a way that it is capable of emulating the thinking patterns of the philosopher Quine, the largest source of data is the entire corpus of Quine. To elaborate, the data includes two files, one of which is a lemmatized text file of the Quine corpus while the other text file is an un-lemmatized\n",
        "version of the same Quine corpus. This model was trained on the lemmatized one. The Quine corpus consists of all of the 228 articles and books that Quine had written in his lifetime (Betti et al. 2020). Furthermore, the corpus consists of a total of 819 document (Betti et al. 2020). So how many words are there in total? When I constructed the ChatQuine tri-gram model, I used Python to test this. The corpus contains 2,150,356 word tokens. To elaborate, the Quine corpus covers a wide range of topics, from different phases of Quine’s life to different genres. Furthermore, according to Betti et al. (2020), Quine’s corpus consists of a “lexical variation” that is\n",
        "rather “high”.\n",
        "\n",
        "Notably, I acquired this datset from Betti et al's research (2020). Due to privacy reasons, I have agreed not to publish this dataset. All I am publishing here is the original code I wrote by myself. Thus, I am not violating the data use agreement I signed with Betti et al's research team. So if you want to make a similar project like ChatQuine, you can use my code but you have to collect the dataset by yourself. Good luck!"
      ],
      "metadata": {
        "id": "tIFNx7184nAU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Result Synopsis**\n",
        "\n",
        "The two randomly generated sentences by ChatQuine are “hypotenuse be equal and opposite line in that book later pron be just these basic disagreement in the order of” and “trapping sentence by deep analysis of the function satisfy by x the hierarchy to which neg and x x y etc. stand in the main business of semantic.” Assessing these outputs by intrinsic evaluation, the terminology and syntax are in agreement with Quine’s philosophy of language, epistemology, and metaphysics.\n",
        "\n",
        "However, these nonhuman outputs lack grammatical accuracy and semantic meaning. This 'stupidity' might result from the small training datasets and unadvanced language models. Thus, in my next project ChatQuine 2.0 (https://github.com/Cameron-Meinsma/ChatQuine), my team trained this chatbot on virtually the entire internet content regarding Quine and a GPT-3.5 model.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Gtu6zTdohRkf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Citations***\n",
        "\n",
        "Programming: https://www.kaggle.com/code/alvations/n-gram-language-model-with-nltk/notebook"
      ],
      "metadata": {
        "id": "hEAswovb1_fI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset: Betti, Arianna. Martin Reynaert, Thijs Ossenkoppele, Yvette Oortwijn, Andrew Salway, and Jelke Bloem. 2020. “Expert Concept-Modeling Ground Truth Construction for Word Embeddings Evaluation in Concept-Focused Domains.” In Proceedings of the 28th International Conference on Computational Linguistics, pages 6690–6702, Barcelona, Spain (Online). International Committee on Computational Linguistics. https://aclanthology.org/2020.coling-main.586/  \n",
        "\n",
        "  (Note: this dataset is not published here due to privacy reasons!)"
      ],
      "metadata": {
        "id": "J81lbpVX0VhO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fm2ST6EhAPK"
      },
      "outputs": [],
      "source": [
        "from nltk.util import pad_sequence\n",
        "from nltk.util import bigrams\n",
        "from nltk.util import ngrams\n",
        "from nltk.util import everygrams\n",
        "from nltk.lm.preprocessing import pad_both_ends\n",
        "from nltk.lm.preprocessing import flatten"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Open our tokenized text file of Quine's work:"
      ],
      "metadata": {
        "id": "GVWl5huDlHJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import io #codecs\n",
        "\n",
        "#As our file is already tokenized, we only need to open the text file\n",
        "if os.path.isfile('/content/drive/MyDrive/Quine_data/QUINEV05FOLIASPACY.ColTextLem.20200516.W2Vnorm.PerlLimit.txt'):\n",
        "    with io.open('/content/drive/MyDrive/Quine_data/QUINEV05FOLIASPACY.ColTextLem.20200516.W2Vnorm.PerlLimit.txt', encoding='utf8') as fin:\n",
        "        text = fin.read()\n",
        "print(text[:100])\n",
        "print(text[1:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1crzuh0jWrx",
        "outputId": "12e81281-d1be-4cc3-8caf-ea267cb2fc0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{{N}} logical formules\n",
            "the connective e of membership be adopt as part of pron primitive logical not\n",
            "{N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize our text:"
      ],
      "metadata": {
        "id": "6Q9hKRzC4d9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try: # Use the default NLTK tokenizer.\n",
        "    from nltk import word_tokenize, sent_tokenize\n",
        "    # Testing whether it works.\n",
        "    # Sometimes it doesn't work on some machines because of setup issues.\n",
        "    word_tokenize(sent_tokenize(\"This is a foobar sentence. Yes it is.\")[0])\n",
        "except: # Use a naive sentence tokenizer and toktok.\n",
        "    import re\n",
        "    from nltk.tokenize import ToktokTokenizer\n",
        "    # See https://stackoverflow.com/a/25736515/610569\n",
        "    sent_tokenize = lambda x: re.split(r'(?<=[^A-Z].[.?]) +(?=[A-Z])', x)\n",
        "    # Use the toktok tokenizer that requires no dependencies.\n",
        "    toktok = ToktokTokenizer()\n",
        "    word_tokenize = word_tokenize = toktok.tokenize"
      ],
      "metadata": {
        "id": "nKeqseFi4JFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text.\n",
        "tokenized_text = [list(map(str.lower, word_tokenize(sent)))\n",
        "                  for sent in sent_tokenize(text)]"
      ],
      "metadata": {
        "id": "J_9s8E9Y4AJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_text[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZU-IT384VfE",
        "outputId": "73404aaf-2f4a-4f5a-96c2-6c9d03ac1910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['{',\n",
              " '{',\n",
              " 'n',\n",
              " '}',\n",
              " '}',\n",
              " 'logical',\n",
              " 'formules',\n",
              " 'the',\n",
              " 'connective',\n",
              " 'e',\n",
              " 'of',\n",
              " 'membership',\n",
              " 'be',\n",
              " 'adopt',\n",
              " 'as',\n",
              " 'part',\n",
              " 'of',\n",
              " 'pron',\n",
              " 'primitive',\n",
              " 'logical',\n",
              " 'notation',\n",
              " 'along',\n",
              " 'with',\n",
              " 'the',\n",
              " 'connective',\n",
              " 'j',\n",
              " 'of',\n",
              " 'joint',\n",
              " 'denial',\n",
              " 'and',\n",
              " 'the',\n",
              " 'quantifier',\n",
              " 'and',\n",
              " 'variable',\n",
              " 'which',\n",
              " 'constitute',\n",
              " 'the',\n",
              " 'notation',\n",
              " 'of',\n",
              " 'quantification',\n",
              " 'by',\n",
              " 'put',\n",
              " 'v',\n",
              " 'between',\n",
              " 'variable',\n",
              " 'pron',\n",
              " 'obtain',\n",
              " 'formulae',\n",
              " 'xfz',\n",
              " 'which',\n",
              " 'be',\n",
              " 'atomic',\n",
              " 'in',\n",
              " 'the',\n",
              " 'sense',\n",
              " 'of',\n",
              " 'have',\n",
              " 'no',\n",
              " 'other',\n",
              " 'formula',\n",
              " 'as',\n",
              " 'part',\n",
              " 'this',\n",
              " 'be',\n",
              " 'the',\n",
              " 'first',\n",
              " 'time',\n",
              " 'atomic',\n",
              " 'formula',\n",
              " 'have',\n",
              " 'come',\n",
              " 'to',\n",
              " 'hand',\n",
              " 'hitherto',\n",
              " 'though',\n",
              " 'formula',\n",
              " 'in',\n",
              " 'general',\n",
              " 'be',\n",
              " 'describe',\n",
              " 'as',\n",
              " 'build',\n",
              " 'up',\n",
              " 'of',\n",
              " 'atomic',\n",
              " 'formula',\n",
              " 'by',\n",
              " 'joint',\n",
              " 'denial',\n",
              " 'and',\n",
              " 'quantifier',\n",
              " 'the',\n",
              " 'atomic',\n",
              " 'formula',\n",
              " 'pron',\n",
              " 'be',\n",
              " 'leave',\n",
              " 'unspecified',\n",
              " 'cf',\n",
              " '{',\n",
              " '{',\n",
              " 'n',\n",
              " '}',\n",
              " '}',\n",
              " 'strictly',\n",
              " 'these',\n",
              " 'newly',\n",
              " 'acquire',\n",
              " 'atomic',\n",
              " 'formula',\n",
              " 'should',\n",
              " 'be',\n",
              " 'describe',\n",
              " 'not',\n",
              " 'as',\n",
              " 'xfz',\n",
              " 'but',\n",
              " 'as',\n",
              " 'xfz',\n",
              " 'for',\n",
              " 'v',\n",
              " 'like',\n",
              " 'all',\n",
              " 'binary',\n",
              " 'connective',\n",
              " 'be',\n",
              " 'to',\n",
              " 'be',\n",
              " 'construe',\n",
              " 'as',\n",
              " 'have',\n",
              " 'a',\n",
              " 'pair',\n",
              " 'of',\n",
              " 'parenthesis',\n",
              " 'associate',\n",
              " 'with',\n",
              " 'pron',\n",
              " 'in',\n",
              " 'practice',\n",
              " 'under',\n",
              " 'the',\n",
              " 'working',\n",
              " 'convention',\n",
              " 'explain',\n",
              " 'in',\n",
              " '{',\n",
              " '{',\n",
              " 'n',\n",
              " '}',\n",
              " '}',\n",
              " 'xfz',\n",
              " 'lose',\n",
              " 'pron',\n",
              " 'parenthesis',\n",
              " 'when',\n",
              " 'pron',\n",
              " 'stand',\n",
              " 'alone',\n",
              " 'or',\n",
              " 'as',\n",
              " 'a',\n",
              " 'component',\n",
              " 'of',\n",
              " 'a',\n",
              " 'conjunction',\n",
              " 'alternation',\n",
              " 'conditional',\n",
              " 'or',\n",
              " 'biconditional',\n",
              " '{',\n",
              " '{',\n",
              " 'n',\n",
              " '}',\n",
              " '}',\n",
              " 'hitherto',\n",
              " 'no',\n",
              " 'actual',\n",
              " 'expression',\n",
              " 'could',\n",
              " 'be',\n",
              " 'cite',\n",
              " 'as',\n",
              " 'formula',\n",
              " 'because',\n",
              " 'of',\n",
              " 'the',\n",
              " 'fact',\n",
              " 'that',\n",
              " 'the',\n",
              " 'atomic',\n",
              " 'formula',\n",
              " 'be',\n",
              " 'not',\n",
              " 'give',\n",
              " 'now',\n",
              " 'however',\n",
              " 'one',\n",
              " 'important',\n",
              " 'sort',\n",
              " 'of',\n",
              " 'formula',\n",
              " 'be',\n",
              " 'definitely',\n",
              " 'fix',\n",
              " 'pron',\n",
              " 'comprise',\n",
              " 'atomic',\n",
              " 'formula',\n",
              " 'of',\n",
              " 'the',\n",
              " 'kind',\n",
              " 'xfz',\n",
              " 'together',\n",
              " 'with',\n",
              " 'all',\n",
              " 'other',\n",
              " 'formula',\n",
              " 'whose',\n",
              " 'atomic',\n",
              " 'part',\n",
              " 'be',\n",
              " 'of',\n",
              " 'this',\n",
              " 'kind',\n",
              " 'such',\n",
              " 'formula',\n",
              " 'will',\n",
              " 'be',\n",
              " 'speak',\n",
              " 'of',\n",
              " 'henceforward',\n",
              " 'as',\n",
              " 'logical',\n",
              " 'formula',\n",
              " 'thus',\n",
              " 'the',\n",
              " 'logical',\n",
              " 'formula',\n",
              " 'comprise',\n",
              " 'first',\n",
              " 'all',\n",
              " 'expression',\n",
              " 'obtainable',\n",
              " 'by',\n",
              " 'put',\n",
              " 'variable',\n",
              " 'x',\n",
              " 'y',\n",
              " 'etc.',\n",
              " 'in',\n",
              " 'the',\n",
              " 'blank',\n",
              " 'of',\n",
              " 't',\n",
              " '{',\n",
              " '{',\n",
              " 'rs',\n",
              " '}',\n",
              " '}',\n",
              " 'second',\n",
              " 'all',\n",
              " 'expression',\n",
              " 'obtainable',\n",
              " 'by',\n",
              " 'put',\n",
              " 'expression',\n",
              " 'of',\n",
              " 'the',\n",
              " 'first',\n",
              " 'totality',\n",
              " 'in',\n",
              " 'the',\n",
              " 'blank',\n",
              " 'of',\n",
              " 'j',\n",
              " 'or',\n",
              " 'after',\n",
              " 'a',\n",
              " 'parenthesize',\n",
              " 'variable',\n",
              " 'third',\n",
              " 'all',\n",
              " 'expression',\n",
              " 'obtainable',\n",
              " 'by',\n",
              " 'put',\n",
              " 'expression',\n",
              " 'of',\n",
              " 'the',\n",
              " 'thus',\n",
              " 'supplement',\n",
              " 'totality',\n",
              " 'in',\n",
              " 'the',\n",
              " 'blank',\n",
              " 'of',\n",
              " 'j',\n",
              " 'or',\n",
              " 'after',\n",
              " 'a',\n",
              " 'parenthesize',\n",
              " 'variable',\n",
              " 'and',\n",
              " 'so',\n",
              " 'on',\n",
              " 'synoptically',\n",
              " 'xfz',\n",
              " 'be',\n",
              " 'a',\n",
              " 'logical',\n",
              " 'formula',\n",
              " 'and',\n",
              " 'if',\n",
              " 'xfz',\n",
              " 'and',\n",
              " 'xfz',\n",
              " 'be',\n",
              " 'logical',\n",
              " 'formula',\n",
              " 'then',\n",
              " 'so',\n",
              " 'be',\n",
              " 'xfz',\n",
              " 'and',\n",
              " 'xfz',\n",
              " 'thus',\n",
              " 'the',\n",
              " 'logical',\n",
              " 'formulê',\n",
              " 'comprise',\n",
              " 'such',\n",
              " 'expression',\n",
              " 'as',\n",
              " 'xfz',\n",
              " 'etc.',\n",
              " 'such',\n",
              " 'of',\n",
              " 'the',\n",
              " 'logical',\n",
              " 'formula',\n",
              " 'as',\n",
              " 'have',\n",
              " 'no',\n",
              " 'free',\n",
              " 'variable',\n",
              " 'e.g.',\n",
              " 'the',\n",
              " 'fourth',\n",
              " 'seventh',\n",
              " 'twelfth',\n",
              " 'and',\n",
              " 'last',\n",
              " 'of',\n",
              " 'the',\n",
              " 'above',\n",
              " 'list',\n",
              " 'constitute',\n",
              " 'the',\n",
              " 'logical',\n",
              " 'statement',\n",
              " 'true',\n",
              " 'or',\n",
              " 'false',\n",
              " 'these',\n",
              " 'four',\n",
              " 'example',\n",
              " 'be',\n",
              " 'as',\n",
              " 'pron',\n",
              " 'happen',\n",
              " 'all',\n",
              " 'false',\n",
              " 'there',\n",
              " 'be',\n",
              " 'no',\n",
              " 'atomic',\n",
              " 'logical',\n",
              " 'statement',\n",
              " 'for',\n",
              " 'the',\n",
              " 'atomic',\n",
              " 'logical',\n",
              " 'formula',\n",
              " 'xfz',\n",
              " 'have',\n",
              " 'free',\n",
              " 'variable',\n",
              " 'the',\n",
              " 'short',\n",
              " 'possible',\n",
              " 'logical',\n",
              " 'statement',\n",
              " 'be',\n",
              " 'those',\n",
              " 'which',\n",
              " 'be',\n",
              " 'closure',\n",
              " 'of',\n",
              " 'the',\n",
              " 'one-variable',\n",
              " 'matrix',\n",
              " 'xfz',\n",
              " 'in',\n",
              " 'other',\n",
              " 'word',\n",
              " 'x',\n",
              " 'xe',\n",
              " 'x',\n",
              " 'and',\n",
              " 'pron',\n",
              " 'alphabetic',\n",
              " 'variant',\n",
              " 'y',\n",
              " 'y',\n",
              " '{',\n",
              " '{',\n",
              " 'n',\n",
              " '}',\n",
              " '}',\n",
              " 'y',\n",
              " '>',\n",
              " 'z',\n",
              " 'z',\n",
              " 't',\n",
              " 'z',\n",
              " 'etc.',\n",
              " 'these',\n",
              " 'statement',\n",
              " 'happen',\n",
              " 'incidentally',\n",
              " 'to',\n",
              " 'be',\n",
              " 'false',\n",
              " 'for',\n",
              " 'pron',\n",
              " 'say',\n",
              " 'that',\n",
              " 'every',\n",
              " 'entity',\n",
              " 'and',\n",
              " 'hence',\n",
              " 'every',\n",
              " 'class',\n",
              " 'be',\n",
              " 'a',\n",
              " 'member',\n",
              " 'of',\n",
              " 'pron',\n",
              " 'many',\n",
              " 'class',\n",
              " 'be',\n",
              " 'indeed',\n",
              " 'member',\n",
              " 'of',\n",
              " 'pron',\n",
              " 'but',\n",
              " 'many',\n",
              " 'also',\n",
              " 'be',\n",
              " 'not',\n",
              " 'the',\n",
              " 'class',\n",
              " 'of',\n",
              " 'cat',\n",
              " 'e.g.',\n",
              " 'be',\n",
              " 'not',\n",
              " 'a',\n",
              " 'cat',\n",
              " 'the',\n",
              " 'short',\n",
              " 'logical',\n",
              " 'statement',\n",
              " 'which',\n",
              " 'be',\n",
              " 'true',\n",
              " 'be',\n",
              " 'xfz',\n",
              " 'and',\n",
              " 'pron',\n",
              " 'alphabetic',\n",
              " 'variant',\n",
              " 'e.g.',\n",
              " 'xfz',\n",
              " 'the',\n",
              " 'truth',\n",
              " '{',\n",
              " '{',\n",
              " 'n',\n",
              " '}',\n",
              " '}',\n",
              " 'i.e.',\n",
              " '~',\n",
              " 'x',\n",
              " 'x',\n",
              " 'e',\n",
              " 'x',\n",
              " 'deny',\n",
              " 'that',\n",
              " 'every',\n",
              " 'entity',\n",
              " 'be',\n",
              " 'a',\n",
              " 'member',\n",
              " 'of',\n",
              " 'pron',\n",
              " 'though',\n",
              " 'allow',\n",
              " 'that',\n",
              " 'some',\n",
              " 'may',\n",
              " 'be',\n",
              " 'this',\n",
              " 'truth',\n",
              " 'will',\n",
              " 'not',\n",
              " 'appear',\n",
              " 'as',\n",
              " 'a',\n",
              " 'theorem',\n",
              " 'until',\n",
              " 'a',\n",
              " 'considerably',\n",
              " 'later',\n",
              " 'point',\n",
              " '{',\n",
              " '{',\n",
              " 'n',\n",
              " '}',\n",
              " '}',\n",
              " '{',\n",
              " '{',\n",
              " 'n',\n",
              " '}',\n",
              " '}',\n",
              " '{',\n",
              " '{',\n",
              " 'n',\n",
              " '}',\n",
              " '}',\n",
              " 'pron',\n",
              " 'will',\n",
              " 'be',\n",
              " 'note',\n",
              " 'that',\n",
              " 'the',\n",
              " 'logical',\n",
              " 'formula',\n",
              " 'contain',\n",
              " 'no',\n",
              " 'name',\n",
              " 'not',\n",
              " 'even',\n",
              " 'name',\n",
              " 'of',\n",
              " 'abstract',\n",
              " 'entity',\n",
              " 'class',\n",
              " 'in',\n",
              " 'the',\n",
              " 'atomic',\n",
              " 'formula',\n",
              " 'xfz',\n",
              " 'the',\n",
              " 'a',\n",
              " 'and',\n",
              " 'xfz',\n",
              " 'be',\n",
              " 'never',\n",
              " 'name',\n",
              " 'but',\n",
              " 'merely',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " 'etc.',\n",
              " 'in',\n",
              " 'effect',\n",
              " 'pronoun',\n",
              " 'cf',\n",
              " '{',\n",
              " '{',\n",
              " 'n',\n",
              " '}',\n",
              " '}',\n",
              " 'the',\n",
              " 'logical',\n",
              " 'formula',\n",
              " 'do',\n",
              " 'indeed',\n",
              " 'comprise',\n",
              " 'statement',\n",
              " 'as',\n",
              " 'well',\n",
              " 'as',\n",
              " 'matrix',\n",
              " 'the',\n",
              " 'statement',\n",
              " 'have',\n",
              " 'definite',\n",
              " 'import',\n",
              " 'not',\n",
              " 'by',\n",
              " 'virtue',\n",
              " 'of',\n",
              " 'exhibit',\n",
              " 'name',\n",
              " 'in',\n",
              " 'place',\n",
              " 'of',\n",
              " 'variable',\n",
              " 'however',\n",
              " 'but',\n",
              " 'merely',\n",
              " 'by',\n",
              " 'virtue',\n",
              " 'of',\n",
              " 'contain',\n",
              " 'enough',\n",
              " 'quantifier',\n",
              " 'to',\n",
              " 'render',\n",
              " 'the',\n",
              " 'variable',\n",
              " 'bind',\n",
              " 'at',\n",
              " 'all',\n",
              " 'occurrence',\n",
              " 'all',\n",
              " 'this',\n",
              " 'be',\n",
              " 'apparent',\n",
              " 'from',\n",
              " 'the',\n",
              " 'foregoing',\n",
              " 'description',\n",
              " 'and',\n",
              " 'the',\n",
              " 'example',\n",
              " 'subsequently',\n",
              " 'indeed',\n",
              " 'the',\n",
              " 'logical',\n",
              " 'formula',\n",
              " 'will',\n",
              " 'be',\n",
              " 'abbreviate',\n",
              " 'through',\n",
              " 'definition',\n",
              " 'in',\n",
              " 'such',\n",
              " 'a',\n",
              " 'way',\n",
              " 'that',\n",
              " 'name',\n",
              " 'of',\n",
              " 'class',\n",
              " 'will',\n",
              " 'take',\n",
              " 'form',\n",
              " 'within',\n",
              " 'pron',\n",
              " 'but',\n",
              " 'such',\n",
              " 'name',\n",
              " 'will',\n",
              " 'have',\n",
              " 'the',\n",
              " 'status',\n",
              " 'merely',\n",
              " 'of',\n",
              " 'shorthand',\n",
              " 'capable',\n",
              " 'always',\n",
              " 'of',\n",
              " 'elimination',\n",
              " 'in',\n",
              " 'favor',\n",
              " 'of',\n",
              " 'the',\n",
              " 'frugal',\n",
              " 'notation',\n",
              " 'describe',\n",
              " 'above',\n",
              " 'pron',\n",
              " 'shall',\n",
              " 'see',\n",
              " 'in',\n",
              " 'subsequent',\n",
              " 'section',\n",
              " 'that',\n",
              " 'the',\n",
              " 'notion',\n",
              " 'of',\n",
              " 'identity',\n",
              " 'relation',\n",
              " 'number',\n",
              " 'function',\n",
              " 'sum',\n",
              " 'product',\n",
              " 'power',\n",
              " 'limit',\n",
              " 'derivative',\n",
              " 'etc.',\n",
              " 'be',\n",
              " 'all',\n",
              " 'definable',\n",
              " 'in',\n",
              " 'term',\n",
              " 'of',\n",
              " 'pron',\n",
              " 'three',\n",
              " 'primitive',\n",
              " 'notational',\n",
              " 'device',\n",
              " 'membership',\n",
              " 'joint',\n",
              " 'denial',\n",
              " 'and',\n",
              " 'quantification',\n",
              " 'with',\n",
              " 'pron',\n",
              " 'variable',\n",
              " 'under',\n",
              " 'those',\n",
              " 'definition',\n",
              " 'every',\n",
              " 'true',\n",
              " 'and',\n",
              " 'every',\n",
              " 'false',\n",
              " 'statement',\n",
              " 'which',\n",
              " 'be',\n",
              " 'couch',\n",
              " 'in',\n",
              " 'purely',\n",
              " 'mathematical',\n",
              " 'term',\n",
              " 'become',\n",
              " 'an',\n",
              " 'abbreviation',\n",
              " 'of',\n",
              " 'a',\n",
              " 'logical',\n",
              " 'formula',\n",
              " 'in',\n",
              " 'particular',\n",
              " 'a',\n",
              " 'logical',\n",
              " 'statement',\n",
              " 'in',\n",
              " 'the',\n",
              " 'sense',\n",
              " 'describe',\n",
              " 'above',\n",
              " 'the',\n",
              " 'three',\n",
              " 'primitive',\n",
              " 'thus',\n",
              " 'provide',\n",
              " 'a',\n",
              " 'complete',\n",
              " 'mathematical',\n",
              " 'language',\n",
              " 'the',\n",
              " 'language',\n",
              " 'be',\n",
              " 'not',\n",
              " 'indeed',\n",
              " 'a',\n",
              " 'convenient',\n",
              " 'one',\n",
              " 'for',\n",
              " 'mathematical',\n",
              " 'practice',\n",
              " 'the',\n",
              " 'simple',\n",
              " 'statement',\n",
              " '{',\n",
              " '{',\n",
              " 'n',\n",
              " '}',\n",
              " '}',\n",
              " '+',\n",
              " '{',\n",
              " '{',\n",
              " 'n',\n",
              " '}',\n",
              " '}',\n",
              " '=',\n",
              " '{',\n",
              " '{',\n",
              " 'n',\n",
              " '}',\n",
              " '}',\n",
              " 'if',\n",
              " 'translate',\n",
              " 'into',\n",
              " 'term',\n",
              " 'of',\n",
              " 'these',\n",
              " 'three',\n",
              " 'primitive',\n",
              " 'would',\n",
              " 'run',\n",
              " 'to',\n",
              " 'a',\n",
              " 'length',\n",
              " 'of',\n",
              " 'many',\n",
              " 'page',\n",
              " 'for',\n",
              " 'mathematical',\n",
              " 'practice',\n",
              " 'demonstration',\n",
              " 'and',\n",
              " 'application',\n",
              " 'of',\n",
              " 'theorem',\n",
              " 'definitional',\n",
              " 'abbreviation',\n",
              " 'be',\n",
              " 'thus',\n",
              " 'indispensable',\n",
              " 'for',\n",
              " 'metamathematical',\n",
              " 'practice',\n",
              " 'on',\n",
              " 'the',\n",
              " 'other',\n",
              " 'hand',\n",
              " 'formulation',\n",
              " 'and',\n",
              " 'investigation',\n",
              " 'of',\n",
              " 'the',\n",
              " 'general',\n",
              " 'notion',\n",
              " 'of',\n",
              " 'formula',\n",
              " 'theorem',\n",
              " 'mathematical',\n",
              " 'truth',\n",
              " 'etc.',\n",
              " 'the',\n",
              " 'reduction',\n",
              " 'of',\n",
              " 'concept',\n",
              " 'to',\n",
              " 'a',\n",
              " 'few',\n",
              " 'primitive',\n",
              " 'be',\n",
              " 'indispensable',\n",
              " 'the',\n",
              " 'subject',\n",
              " 'matter',\n",
              " 'of',\n",
              " 'pron',\n",
              " 'metamathematical',\n",
              " 'investigation',\n",
              " 'be',\n",
              " 'thereby',\n",
              " 'simplified',\n",
              " 'to',\n",
              " 'the',\n",
              " 'point',\n",
              " 'of',\n",
              " 'manageability',\n",
              " 'cf',\n",
              " 'introduction',\n",
              " 'reduction',\n",
              " 'of',\n",
              " 'the',\n",
              " 'concept',\n",
              " 'of',\n",
              " 'mathematic',\n",
              " 'to',\n",
              " 'the',\n",
              " 'three',\n",
              " 'primitive',\n",
              " 'be',\n",
              " 'of',\n",
              " 'theoretical',\n",
              " 'significance',\n",
              " 'also',\n",
              " 'as',\n",
              " 'afford',\n",
              " 'a',\n",
              " 'measure',\n",
              " 'of',\n",
              " 'the',\n",
              " 'net',\n",
              " 'conceptual',\n",
              " 'presupposition',\n",
              " 'involve',\n",
              " 'in',\n",
              " 'mathematical',\n",
              " 'theory',\n",
              " 'and',\n",
              " 'the',\n",
              " 'definition',\n",
              " 'be',\n",
              " 'significant',\n",
              " 'as',\n",
              " 'an',\n",
              " 'analysis',\n",
              " 'of',\n",
              " 'the',\n",
              " 'various',\n",
              " 'derivative',\n",
              " 'mathematical',\n",
              " 'concept',\n",
              " 'frege',\n",
              " 'be',\n",
              " 'the',\n",
              " 'first',\n",
              " 'to',\n",
              " 'show',\n",
              " '{',\n",
              " '{',\n",
              " 'n',\n",
              " '}',\n",
              " '}',\n",
              " 'that',\n",
              " 'the',\n",
              " 'notion',\n",
              " 'of',\n",
              " 'arithmetic',\n",
              " 'could',\n",
              " 'be',\n",
              " 'define',\n",
              " 'in',\n",
              " 'purely',\n",
              " 'logical',\n",
              " 'term',\n",
              " 'a',\n",
              " 'more',\n",
              " 'refined',\n",
              " 'and',\n",
              " 'detailed',\n",
              " 'construction',\n",
              " 'of',\n",
              " 'arithmetic',\n",
              " 'and',\n",
              " 'derivative',\n",
              " 'discipline',\n",
              " 'from',\n",
              " 'logic',\n",
              " 'be',\n",
              " 'carry',\n",
              " 'out',\n",
              " 'by',\n",
              " 'whitehead',\n",
              " 'and',\n",
              " 'russell',\n",
              " 'in',\n",
              " 'the',\n",
              " 'reduction',\n",
              " 'of',\n",
              " 'logic',\n",
              " 'in',\n",
              " 'turn',\n",
              " 'to',\n",
              " 'the',\n",
              " 'three',\n",
              " 'present',\n",
              " 'primitive',\n",
              " 'one',\n",
              " 'essential',\n",
              " 'step',\n",
              " 'be',\n",
              " 'russell',\n",
              " \"'\",\n",
              " 's',\n",
              " 'discovery',\n",
              " 'of',\n",
              " 'how',\n",
              " 'to',\n",
              " 'define',\n",
              " 'complex',\n",
              " 'term',\n",
              " 'in',\n",
              " 'context',\n",
              " 'cf',\n",
              " '{',\n",
              " '{',\n",
              " 'n',\n",
              " '}',\n",
              " '}',\n",
              " '{',\n",
              " '{',\n",
              " 'rs',\n",
              " '}',\n",
              " '}',\n",
              " 'a',\n",
              " 'second',\n",
              " 'be',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_text[0][:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT2-UP5z4zqY",
        "outputId": "2f34ff7e-a030-4311-bb10-727b6f885bce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['{', '{', 'n', '}', '}', 'logical', 'formules', 'the', 'connective', 'e', 'of', 'membership', 'be', 'adopt', 'as', 'part', 'of', 'pron', 'primitive', 'logical', 'notation', 'along', 'with', 'the', 'connective', 'j', 'of', 'joint', 'denial', 'and', 'the', 'quantifier', 'and', 'variable', 'which', 'constitute', 'the', 'notation', 'of', 'quantification', 'by', 'put', 'v', 'between', 'variable', 'pron', 'obtain', 'formulae', 'xfz', 'which']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Padding sentences before splitting them into ngrams."
      ],
      "metadata": {
        "id": "56eHrWGOyxzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the tokenized text for 3-grams language modelling\n",
        "n = 3\n",
        "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)"
      ],
      "metadata": {
        "id": "R_3hRBRI5e7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training an N-gram Model:"
      ],
      "metadata": {
        "id": "57tTWQAz5tkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.lm import MLE\n",
        "model = MLE(n) # Train a 3-grams model, previously we set n=3"
      ],
      "metadata": {
        "id": "geffHlWc59CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing the MLE model, creates an empty vocabulary"
      ],
      "metadata": {
        "id": "Gtu1-XL96W3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(model.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVeDNiWI6Yyi",
        "outputId": "7a92cf92-232b-4976-aeed-8a75f25accb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data, padded_sents)\n",
        "print(model.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4PvFilT6dH9",
        "outputId": "d31f6280-1120-4e32-e386-84b931a60a65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Vocabulary with cutoff=1 unk_label='<UNK>' and 25519 items>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(model.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDiaBFsz67UQ",
        "outputId": "76a61783-748a-4c18-a144-fa0472e3a607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25519"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The vocabulary helps us handle words that have not occurred during training."
      ],
      "metadata": {
        "id": "_jhvPeUs7Bag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.vocab.lookup(tokenized_text[0][:50]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgU9H0A-7C8T",
        "outputId": "b7935b8b-4436-4694-f046-59821d60d651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('{', '{', 'n', '}', '}', 'logical', 'formules', 'the', 'connective', 'e', 'of', 'membership', 'be', 'adopt', 'as', 'part', 'of', 'pron', 'primitive', 'logical', 'notation', 'along', 'with', 'the', 'connective', 'j', 'of', 'joint', 'denial', 'and', 'the', 'quantifier', 'and', 'variable', 'which', 'constitute', 'the', 'notation', 'of', 'quantification', 'by', 'put', 'v', 'between', 'variable', 'pron', 'obtain', 'formulae', 'xfz', 'which')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If we lookup the vocab on unseen sentences not from the training data,\n",
        "# it automatically replace words not in the vocabulary with `<UNK>`.\n",
        "print(model.vocab.lookup('language is never random lah .'.split()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59t0RsAw7XOX",
        "outputId": "21c7e0e0-1d38-4592-cadc-802154eb4ca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('language', 'is', 'never', 'random', '<UNK>', '<UNK>')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the N-gram Language Model:\n",
        "\n",
        "When it comes to ngram models the training boils down to counting up the ngrams from the training corpus"
      ],
      "metadata": {
        "id": "3fnu75mk7kEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_URz7t-37lWn",
        "outputId": "8dc3b511-6351-40e7-9f2f-faa5febc793e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<NgramCounter with 3 ngram orders and 5909169 ngrams>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate score how probable words are in certain contexts.\n",
        "\n",
        "This being MLE, the model returns the item's relative frequency as its score."
      ],
      "metadata": {
        "id": "0elrvSPb8Iii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.score('logical') # i.e.('language')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAKvwawu8Oj6",
        "outputId": "18afa8bb-7eb2-417e-f29f-c1d56d8d4f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0010656315301026946"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.score('is', 'logical'.split())  # P('is'|'language')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hT8xsUYh8ZmF",
        "outputId": "e22050ff-7747-40b7-aac6-065cd99b6d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Items that are not seen during training are mapped to the vocabulary's \"unknown label\" token. This is \"\" by default."
      ],
      "metadata": {
        "id": "ZXLnrThX8sw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.score(\"<UNK>\") == model.score(\"hahaha\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jOvswlp8uBr",
        "outputId": "af81b5cc-fbb3-476b-ad3e-5dd9e6f60769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generation using N-gram Language Model:"
      ],
      "metadata": {
        "id": "nnnzZerD8_Y2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use our model to generate a random text:"
      ],
      "metadata": {
        "id": "1cVrnQWW9OEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.generate(20, random_seed=7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVRAVqk69BgX",
        "outputId": "d1601fe9-85d6-49c4-b4c3-cae6a118266d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hypotenuse', 'be', 'equal', 'and', 'opposite', 'line', 'in', 'that', 'book', 'later', 'pron', 'be', 'just', 'these', 'basic', 'disagreement', 'in', 'the', 'order', 'of']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make the generated text human-like by cleaning:"
      ],
      "metadata": {
        "id": "xBokn67V9Rj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "detokenize = TreebankWordDetokenizer().detokenize\n",
        "\n",
        "def generate_sent(model, num_words, random_seed=42):\n",
        "    \"\"\"\n",
        "    :param model: An ngram language model from `nltk.lm.model`.\n",
        "    :param num_words: Max no. of words to generate.\n",
        "    :param random_seed: Seed value for random.\n",
        "    \"\"\"\n",
        "    content = []\n",
        "    for token in model.generate(num_words, random_seed=random_seed):\n",
        "        if token == '<s>':\n",
        "            continue\n",
        "        if token == '</s>':\n",
        "            break\n",
        "        content.append(token)\n",
        "    return detokenize(content)"
      ],
      "metadata": {
        "id": "937cKjZ-9Z_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_sent(model, 20, random_seed=7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nDu8aGo59mtR",
        "outputId": "6729a653-cf92-44e6-9715-8f59cf5b54d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hypotenuse be equal and opposite line in that book later pron be just these basic disagreement in the order of'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_sent(model, 28, random_seed=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Zp0MJyI394zG",
        "outputId": "c1e7ddb4-9b01-4734-8383-0a8278452c3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'trapping sentence by deep analysis of the function satisfy by x the hierarchy to which neg and x x y etc. stand in the main business of semantic'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ]
}